def ngramanalysis(n):
    import os
    import string
    from collections import Counter
    from cleanfile import cleanfile
    from genngram import genngram
    import csv
    #reading interviewees' ID's and hence lastnames from  keys.xls to a distionary
    from xlrd import open_workbook
    workbook = open_workbook('keys.xls')
    sheet=workbook.sheets()[0]
    number_of_rows = sheet.nrows
    keys={}
    for i in range (0, number_of_rows):
        keys[i+1]=sheet.cell(i,1).value.lower()
    cleanedtext=''
    alltext=''
    #reading all file names in folder "Transcript"
    files=os.listdir('Transcript')
    for i in range (1,len(files)):
        #try except to print out any error 
        #this step is crucial in identifying broken transcripts (more details in readme.md)
        try:
            #reading transcripts and converting to lower case words
            text=open('Transcript/'+files[i], 'r').read().lower()
            #interviewee lastname from distionary
            interviewee=keys[int(files[i].split('.')[0])]
            #calling generic function cleanfile to filter out content other than interviewee's
            #also taking out stop words, punctuations, digits, and extra white spaces
            #expanding contractions
            words=cleanfile(text,interviewee)
            #alltext contains the original content of all cleaned transcripts
            alltext=alltext+words+" "
            #cleanedtext on the other hand, only allow a word to appear once in one transcript
            wordslist=set(words.split())
            words=' '.join(wordslist)
            cleanedtext=cleanedtext+words+" "
        except Exception:
            #print out file names of broken transcripts
            print(files[i].split('.')[0])
            continue
    cleanedtext=cleanedtext.strip()
    #finding top 1000 most common n-gram in terms of number of people who mention it
    ##This list is generated by counting a bigram one time even if it appears in a transcript several times
    ##(i.e. multiple appearances in one transcript is counted as one time)
    cleanedlist=Counter(genngram(cleanedtext, n)).most_common()[:1000]
    #writing results to a .txt file
    f=open("results/1000 "+str(n)+"grams by population.txt", "w+")
    #cleaning original content in case file not empty
    f.seek(0)
    f.truncate()
    f.write('\n'.join('{} {}'.format(x[0],x[1]) for x in cleanedlist))
    f.close()
    alltext=alltext.strip()
    #finding top 1000 most common n-gram in terms of frequency that it appears in all transcripts
    ##This list is generated by counting a bigram multiple times if it appears in a transcript several times
    ##(i.e. multiple appearances in one transcript is counted as multiple times)
    alltextlist=Counter(genngram(alltext, n)).most_common()[:1000]
    #writing results into a .txt file
    f=open("results/1000 "+str(n)+"grams by frequency.txt", "w+")
    f.seek(0)
    f.truncate()
    f.write('\n'.join('{} {}'.format(x[0],x[1]) for x in alltextlist))
    f.close()
    return None